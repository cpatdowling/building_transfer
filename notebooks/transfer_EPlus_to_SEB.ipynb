{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer EPLus Medium Office Building to SEB state transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cells will fill entire width of the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "#Tells Jupyter to reload custom classes from scratch everytime an import cell is run, if you edit a custom class\n",
    "#between imports Jupyter would otherwise need to be restarted completely. Buyer beware: old class objects in the \n",
    "#current namespace will cause errors at execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#switches matplotlib to show plots in the browser rather than opening a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always forget to do this for better looking plots\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "#from cvxpy import *\n",
    "from statsmodels.tsa import stattools\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "#energyplus processing functions\n",
    "from eplusprocessing import *\n",
    "from buildsys_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEB helper functions\n",
    "\n",
    "def read_file_timestamp(strin):\n",
    "    out = datetime.datetime.strptime(strin, '%Y-%m-%dT%H:%M:%S')\n",
    "    return(out)\n",
    "\n",
    "def file_name_from_timestamp(dtobj):\n",
    "    out = datetime.datetime.strftime(dtobj, \"%Y-%m-%d\")\n",
    "    return(out)\n",
    "\n",
    "def read_volttron_file(fobj, col=1):\n",
    "    p = []\n",
    "    lines = fobj.readlines()\n",
    "    lines.pop(0)\n",
    "    for line in lines:\n",
    "        p.append(float(line.strip().split(\",\")[col]))\n",
    "    return(p)\n",
    "\n",
    "def utc_offset(data_list):\n",
    "    first = data_list[0:480]\n",
    "    last = data_list[480:]\n",
    "    return(last + first)\n",
    "\n",
    "def to_celsius(fah):\n",
    "    c = (fah - 32.0)/1.8\n",
    "    return(c)\n",
    "\n",
    "def norm_array(arr):\n",
    "    return(preprocessing.minmax_scale(arr, axis=0))\n",
    "\n",
    "def norm_array_custom(arr, minimum, maximum):\n",
    "    arr_out = (arr - minimum)/(maximum - minimum)\n",
    "    return(arr_out)\n",
    "\n",
    "def circularize_normed_data(arr):\n",
    "    #assume data normalized to 0-1 interval\n",
    "    x = np.sin(2*np.pi*arr)\n",
    "    y = np.cos(2*np.pi*arr)\n",
    "    return(x, y)\n",
    "\n",
    "filedates = []\n",
    "for i in range(21,27): #day 27 is missing data\n",
    "    filedates.append(file_name_from_timestamp(datetime.datetime(year=2018, month=6, day=i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_length = 60 #minutes\n",
    "bins = 24 #1440/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/chase/projects/buildnn/data/PNNL/SEB/\"\n",
    "months = [\"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\"]\n",
    "\n",
    "powerdata = []\n",
    "timedata = []\n",
    "daydata = []\n",
    "dtdata = []\n",
    "\n",
    "for month in months:\n",
    "    path = datadir + \"/\" + month + \"/\" + \"ELECTRIC_METER/WholeBuildingDemand/\"\n",
    "    filedates = sorted(os.listdir(path))\n",
    "    for f in filedates:\n",
    "        with open(path + f, \"r\") as d:\n",
    "            p = []\n",
    "            t = []\n",
    "            lines = d.readlines()\n",
    "            lines.pop(0)\n",
    "            for line in lines:\n",
    "                tokens = line.strip().split(\",\")\n",
    "                p.append(float(tokens[1]))\n",
    "                t.append(read_file_timestamp(tokens[0]))\n",
    "                \n",
    "            #p = utc_offset(p)\n",
    "            #t = utc_offset(t)\n",
    "            \n",
    "            #moving average according to global moving_average_length time in minutes\n",
    "            pavg = []\n",
    "            tavg = []\n",
    "            wdavg = []\n",
    "            \n",
    "            for b in range(bins):\n",
    "                pavg.append(np.nanmean(p[b*moving_average_length:(b+1)*moving_average_length]))\n",
    "                try:\n",
    "                    tavg.append(t[b*moving_average_length].hour*60 + t[b*moving_average_length].minute)\n",
    "                    wdavg.append(t[b*moving_average_length].weekday())\n",
    "                    dtdata.append(t[b*moving_average_length])\n",
    "                except:\n",
    "                    tavg.append(np.nan)\n",
    "                    wdavg.append(np.nan)\n",
    "                    dtdata.append(np.nan)\n",
    "            powerdata += pavg\n",
    "            timedata += tavg\n",
    "            daydata += wdavg\n",
    "\n",
    "powerdata = np.asarray(powerdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airunits = [\"AHU1\"]#, \"AHU2\", \"AHU3\", \"AHU4\"]\n",
    "airvars = [\"ExhaustAirFlow\", \"HotWaterFlowRate\", \"ExhaustFanPower\", \n",
    "           \"OutdoorAirTemperature\", \"SupplyFanPower\", \"MixedAirTemperature\", \"ReturnAirFlow\", \n",
    "           \"ReturnAirTemperature\", \"SupplyAirFlow\", \"SupplyFanPower\", \"ReturnFanPower\", \n",
    "           \"DischargeAirTemperature\", \"ChilledWaterValvePosition\", \"HotWaterValvePosition\", \n",
    "           \"HotWaterCoilTemperature\", \"HeatingPercent\", \"DuctStaticPressure\", \"OutdoorAirFlow\",\n",
    "           \"HotWaterSupplyTemperature\", \"HotWaterReturnTemperature\", \"HotWaterValveTemperature\",\n",
    "           \"HrWheelSpeed\", \"SupplyFanSpeedPercent\"]\n",
    "vavunits = [\"VAV100\"]#, \"VAV102\", \"VAV118\", \"VAV119\", \"VAV120\", \"VAV121\", \"VAV129\", \"VAV131\", \"VAV133\",\n",
    "            #\"VAV136\", \"VAV142\", \"VAV143\", \"VAV150\"]\n",
    "vavvars = [\"ZoneCoolingTemperatureSetPoint\", \"ZoneTemperature\", \"ZoneHeatingTemperatureSetPoint\", \n",
    "           \"ZoneTemperatureSetPoint\", \"ZoneDischargeAirTemperature\", \"ZoneAirFlow\"]\n",
    "\n",
    "ahudata = {}\n",
    "vavdata = {}\n",
    "\n",
    "for a in airunits:\n",
    "    ahudata[a] = {}\n",
    "    for m in airvars:\n",
    "        ahudata[a][m] = []\n",
    "        \n",
    "for v in vavunits:\n",
    "    vavdata[v] = {}\n",
    "    for m in vavvars:\n",
    "        vavdata[v][m] = []\n",
    "\n",
    "for month in months:\n",
    "    for a in airunits:\n",
    "        print(month, \": \", a)\n",
    "        path = datadir + month + \"/\" + a\n",
    "        msrmnts = os.listdir(path)\n",
    "        for m in msrmnts:\n",
    "            if m in airvars:\n",
    "                filedates = sorted(os.listdir(path + \"/\" + m))\n",
    "                for f in filedates:\n",
    "                    with open(path + \"/\" + m + \"/\" + f, 'r') as d:\n",
    "                        p = read_volttron_file(d) #utc_offset(read_volttron_file(d))\n",
    "                        pavg = []\n",
    "                        for b in range(bins):\n",
    "                            pavg.append(np.nanmean(p[b*moving_average_length:(b+1)*moving_average_length]))\n",
    "                        ahudata[a][m] += pavg\n",
    "                        \n",
    "            if m in vavunits:\n",
    "                vav_true_vars = os.listdir(path + \"/\" + m)\n",
    "                for v in vav_true_vars:\n",
    "                    if v in vavvars:\n",
    "                        filedates = sorted(os.listdir(path + \"/\" + m + \"/\" + v))\n",
    "                        for f in filedates:\n",
    "                            with open(path + \"/\" + m + \"/\" + v + \"/\" + f, 'r') as d:\n",
    "                                p = read_volttron_file(d) #utc_offset(read_volttron_file(d))\n",
    "                                pavg = []\n",
    "                                for b in range(bins):\n",
    "                                    pavg.append(np.nanmean(p[b*moving_average_length:(b+1)*moving_average_length]))\n",
    "                                vavdata[m][v] += pavg\n",
    "\n",
    "for m in ahudata[a]:\n",
    "    ahudata[a][m] = np.asarray(ahudata[a][m])\n",
    "\n",
    "for v in vavdata:\n",
    "    for mv in vavdata[v]:\n",
    "        vavdata[v][mv] = np.asarray(vavdata[v][mv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in ahudata:\n",
    "    for m in ahudata[a]:\n",
    "        print(a, \", \", m, \", \", len(ahudata[a][m]))\n",
    "        \n",
    "for a in vavdata:\n",
    "    for v in vavdata[a]:\n",
    "        print(a, \", \", v, \", \", len(vavdata[a][v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "conda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
